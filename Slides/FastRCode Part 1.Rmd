---
title: 'Let''s Make Your R Code FastR: Part1'
author: "Nikola Surjanovic"
date: "Simon Fraser University"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE) # Might want to turn on warnings 

my_pkgs <- c("knitr", "xtable", "bench", "ggbeeswarm", "profvis")
need_pkgs <- my_pkgs[!(my_pkgs %in% installed.packages())]
if (length(need_pkgs) > 0) {
  install.packages(need_pkgs)
}
```

<!-- From https://stackoverflow.com/questions/42690955/how-to-insert-footnotes-in-ioslides-presentations-using-rmarkdown, Martin Schmelzer -->
<style>
div.footnotes {
  position: absolute;
  bottom: 0;
  margin-bottom: 10px;
  width: 80%;
  font-size: 0.6em;
}
</style>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

<script>
  $(document).ready(function() {
    $('slide:not(.backdrop):not(.title-slide)').append('<div class=\"footnotes\">');

    $('footnote').each(function(index) {
      var text  = $(this).html();
      var fnNum = (index+1).toString().sup();
      $(this).html(text + fnNum);

      var footnote   = fnNum + ': ' + $(this).attr('content') + '<br/>';
      var oldContent = $(this).parents('slide').children('div.footnotes').html();
      var newContent = oldContent + footnote;
      $(this).parents('slide').children('div.footnotes').html(newContent);
    });
  });
</script>


# Introductions
## Introductions
### About Me
First-year Master's student studying Statistics  

Research interests: machine learning, goodness-of-fit

### How About You?



## Why Are We Here?
How experienced are you with R? 

What would you like to learn today?  

 - This is "Part 1", but we can cover more (or less)




## Outline
1. Why is R "slow"?

2. Timing Your R Code

3. Vectorization and Memory Allocation

4. Quick Fixes (That Make a Big Difference)

5. Advanced: Parallel Problems, Rcpp



# Why is R "slow"?
## Why is R "slow"?
[Insert funny picture here.]



## Why is R "slow"?
Often, R is "fast enough"

<footnote content="Hadley Wickham, Advanced R book, http://adv-r.had.co.nz/"> "The overriding concern for R-core is not to make R fast, but to build a stable platform for data analysis and statistics."</footnote>



## Language vs. Implementation
Difference between language and implementation

Alternatives: pqR, Renjin, FastR, etc.




# Timing Your R Code
## Timing Your R Code
Bottlenecks need to be identified

Don't waste time optimizing code that is already fast enough




## Profiling / Timing Code
Depending on the circumstances, we can use one of:

- <b>profvis()</b>
- <b>bench::mark()</b>
- microbenchmark()
- system.time()
- utils::Rprof()
- utils::summaryRprof()



## bench::mark()
Great for code that takes several nano or milliseconds to run

Example: compare two "sqrt" functions



## bench::mark() - Example
```{r, echo=TRUE, results='hide'}
library(bench)

x <- runif(100)
bm1 <- bench::mark(
  x^0.5,
  sqrt(x)
)
```



## bench::mark() - Example
```{r, echo=FALSE}
bm1
```



## bench::mark() - Example
```{r, echo=FALSE}
plot(bm1)
```



## bench::mark() - Limitations
Useful, but...

Let's see what we can do with profvis()



## profvis() - Example
Consider the function
```{r}
f <- function() {
  pause(0.1)
  g()
  h()
}
g <- function() {
  pause(0.1)
  h()
}
h <- function() {
  pause(0.1)
}
```



## profvis() - Example
Let's "profile" the function, f(), using profvis().

First, put f() in another file and then source that file.
```{r}
library(profvis)
source("../Simple R Functions.R")
profvis(f())
```



## profvis() - What Do We See?
Flame graph: memory and time

Call stack




# Vectorization and Memory Allocation
## Vectorization
Don't think about elements of a vector

- Think about the entire vector as a unit

Loops in a vectorized function are in C

- Less overhead --> faster in C



## Vectorization - Example 1
Add two numeric vectors together, element by element

Non-vectorized version:
```{r}
vec1 <- 1:100
vec2 <- 101:200
vec3 <- numeric(100)

add_vecs1 <- function(vec1, vec2) {
  for (i in 1:length(vec1)) {
    vec3[i] <- vec1[i] + vec2[i]
  }
  return(vec3)
}
```



## Vectorization - Example 1
Vectorized version:
```{r}
add_vecs2 <- function(vec1, vec2) {
  vec3 <- vec1 + vec2
  return(vec3)
}
```



## Vectorization - Example 1
How do the times compare?
```{r}
bm2 <- bench::mark(
  add_vecs1(vec1, vec2),
  add_vecs2(vec1, vec2)
)
bm2
```



## Vectorization - Problem #1
The sample variance for observations $x_1, \ldots, x_n$ is
$$  \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2, $$
where $\bar{x}$ is the sample average.

<b>Problem 1:</b> Given a vector, "vec" with $n$ (numeric) observations, write a vectorized R function that returns the sample variance.

<!-- Use the R code chunk below to answer the practice problem. -->
```{r}














```







<!-- Warning! A possible solution is below. Don't look if you want to try to solve the problem yourself! -->





## Vectorization - Problem #1 (Answer)
```{r}
myvar <- function(vec) {
  n <- length(vec)
  return( 1/(n-1) * sum((vec - mean(vec))^2) )
}
myvar(1:10)
var(1:10)
```



## Vectorization (Again)
It is difficult to overemphasize vectorization in R!

There is almost always a way to vectorize

Useful functions: cumsum(), rowSums(), rowMeans(), etc.



## Preallocation - Example
This mistake can be seen (mostly out of carelessness)

Not preallocating:
```{r}
makemat1 <- function(nrow, ncol, seed) {
  set.seed(seed)
  mymat <- rnorm(ncol, 0, 1)
  for (i in 2:nrow) {
    mymat <- rbind(mymat, rnorm(ncol, 0, 1))
  }
  return(unname(mymat))
}
```



## Preallocation - Example
Preallocating:
```{r}
makemat2 <- function(nrow, ncol, seed) {
  set.seed(seed)
  mymat <- matrix(NA, nrow=nrow, ncol=ncol)
  for (i in 1:nrow) {
    mymat[i, ] <- rnorm(ncol, 0, 1)
  }
  return(mymat)
}
```

Even better:
```{r}
makemat3 <- function(nrow, ncol, seed) {
  set.seed(seed)
  mymat <- matrix(rnorm(nrow*ncol, 0, 1), nrow=nrow, ncol=ncol, byrow = TRUE)
  return(mymat)
}
```



## Preallocation - Example
```{r}
bm3 <- bench::mark(
  makemat1(nrow=10,ncol=10,seed=9823),
  makemat2(nrow=10,ncol=10,seed=9823),
  makemat3(nrow=10,ncol=10,seed=9823)
)
bm3
```



## Preallocation - What's Happening?
Basically, whenever possible, state how much "memory" you will use at the beginning

Otherwise, R might be copying and moving your object around whenever you make a modification



## Copy-on-Modify and Modify-in-Place
Consider the following (somewhat surprising) example:
```{r}
X <- data.frame(matrix(rnorm(10000), ncol=3))
medians <- vapply(X, median, numeric(1))

cat(tracemem(X), "\n")
```



## Copy-on-Modify and Modify-in-Place
```{r}
for (i in 1:3) {
  X[[i]] <- X[[i]] - medians[[i]]
}
untracemem(X)
```




# Quick Fixes (That Make a Big Difference)
## Matrix Inversion - Not Necessary?
Often, we need to compute $A^{-1} b$, for a matrix $A$, and vector $b$.

Although the answer is the same, there is a difference between two methods:

 - Finding $A^{-1}$ and multiplying by $b$

 - Finding $A^{-1} b$
 
Think: the former uses Gaussian elimination and multiplication, the latter just uses Gaussian elimination



## Matrix Inversion - Not Necessary?
Matrix inversion in R with the solve() function

Consider the two examples:
```{r, cache=TRUE}
set.seed(29581)
# A <- matrix(rnorm(5000^2, 0, 1), nrow=5000, ncol=5000)
# b <- rnorm(5000, 0, 1)

# solve(A) %*% b # Get A inverse, and then multiply by b
# solve(A, b) # Get A inverse * b in one step!
```



## Matrix Inversion - Not Necessary?
Let's compare the times:
```{r, cache=TRUE}
# system.time(solve(A) %*% b) # 89.65 seconds
# system.time(solve(A, b)) # 19 seconds
```



## Matrix Inversion - Not Necessary?
I have personally used this trick <b>extensively</b>

Others have also saved <b>a lot</b> of time with this trick



## Use Linear Algebra Whenever Possible
The default BLAS (Basic Linear Algebra Subprogram) is good
 
 - Doesn't do the calculations in R :)
 
Use linear algebra techniques whenever you can

Use order of operations wisely!



## Linear Algebra - Example
I won't give code here
 
 - Not really specific to R

Regression: $X \hat{\beta} = X (X^\top X)^{-1} X^\top y$

$\left(X (X^\top X)^{-1} X^\top \right) y$ versus $X \left((X^\top X)^{-1} \left(X^\top y\right)\right)$

"Big Data": the difference can be HUGE!



## Useful Functions



## The Apply Family



## Checkpoint - Problem #2
That's all for this section

Small "competition": try to rewrite the following code

Goal: make the code as fast as possible (there are small prizes)

- Use system.time(), third column

- Original time:  My new time: 

<b>See the Rmd file for the problem</b>



<!-- 
Problem #2
Try to make your R code as fast as possible
First, you must figure out what the code below is doing
Then, rewrite the code in a separate code chunk and use system.time() to get an estimate
-->

<!-- DO NOT try to make this part of the code faster!!!  -->
```{r problem2prep, echo=FALSE, results='hide'}

```
<!-- DO NOT try to make this part of the code faster!!!  -->


<!-- DO try to make this part of the code faster!!!  -->
```{r problem2, echo=FALSE, results='hide'}
# The original code
```
<!-- DO try to make this part of the code faster!!!  -->


```{r problem2_you, echo=FALSE, results='hide'}
# Your code
```








## Checkpoint - Problem #2
<!-- My solution is below -->
```{r problem2_nikola, echo=FALSE, results='hide'}
# My solution (not necessarily the best!)
```





# Advanced Topics
## Parallel Computing in R
Say I have 4 cores

I will probably use 3 of them to run the code in parallel

Roughly speaking, 3x faster

- But, if you have Compute Canada access...



## Rcpp
Good if for loops are unavoidable

Write C++ code within R

I have seen <b>up to 20x faster</b> (maybe even more) implementations with this method!

Requires more effort (usually) than just running code in parallel



## Advanced Topics
Let's vote:

- Parallel computing in R

- Rcpp (Using C++ within R)
  
These topics were intended to be in Part 2 of the workshop (over the summer)



# Advanced Topics: Parallel Computing in R




# Advanced Topics: Rcpp
